\chapter{各種アルゴリズムの詳細}
\label{chap:alg}
\section{提案手法のアルゴリズム}
提案手法のアルゴリズムの疑似コードをAlgorithm\ref{alg:myalg-1}，Algorithm\ref{alg:myalg-2}に示す．
\begin{algorithm}
    
    \caption{提案手法のアルゴリズム(part1)}
    \label{alg:myalg-1}
    \begin{algorithmic}[1]
        \State $t$: 手法を適用する探索木
        \State $T$: 状態遷移関数
        \State $l$: 盤面の収集を行う手数
        \State $k$: 一度に集める盤面の数
        \State $\zeta(s, s')$: ノード$s$から$s'$までの軌道
        
       
        \Function{MyAlgorithm}{$s_{start}, a, l, k$}
           \State $s_{now}\gets s_{start}$
           \State $a_{now}\gets a$
           \State $Z_0 \gets$\Call{CollectBoards}{$s_{now}, a_{now}, l, k$}
           \State $(Z_0 =\{\zeta(s_{start}, {s'}_1), ..., \zeta(s_{start}, {s'}_{k^l})\})$
           \State $ Z \gets$ empty list
           \For {each $\zeta(s_{start}, {s'}_i)$ in $Z_0$}
             \State $\zeta(s_{start}, s_{{edge}_i}) \gets$ \Call{Traverse}{${s'}_i, \zeta(s_{start}, {s'}_i)$}
             \State $\zeta(s_{start}, s_{{edge}_i})$を$Z$の末尾に追加
           \EndFor
           \State 収集された終了状態の集合$S(=\{s_{edge_1},s_{edge_2}, ..., s_{edge_{k^l}}\})$を任意の共通項$c$で副集合$\{S_1, S_2, ..., S_q\}$に分割する
           \State 最も要素数の多い副集合$S_{max}$中の各要素$\{s_{e_1}, s_{e_2}, ...,  s_{e_u}\}$
           \State に対応する軌道の集合$Z_{max}(=\{\zeta(s_{start}, s_{e_1}), \zeta(s_{start}, s_{e_2}), ..., \zeta(s_{start}, s_{e_u})\})$を保存
           \State \Return $Z_{max}$
        \EndFunction
    \end{algorithmic}
\end{algorithm}
\begin{algorithm}
    
    \caption{提案手法のアルゴリズム(part2)}
    \label{alg:myalg-2}
    \begin{algorithmic}[1]    
    \scriptsize   
        \Function{CollectBoards}{$s, a, l, k$}
           \State $s_{now} \gets T(s, a)$
           
           \State $Z \gets $ empty queue
            \If{$s$が未探索のノード($N(s)=0$)または終了状態のとき}
             \Return  $Z$
            \EndIf
           \State 訪問回数$N(s)$から上位$k$の行動$\{a_1, a_2, ..., a_{k}\}(=\alpha)$を取り出す
           \For {each $a_i$ in $\alpha$}
             
             \State $s_{{next}_i} \gets T(s_{now}, a_i)$
             \State $\zeta(s_{now},s_{{next}_i})(=\{s_{now}, a_i, s_{{next}_i}\})$を$Z$の末尾に追加
           \EndFor
           \If{l=1}
             \Return $Z$
           \EndIf
           \State $i \gets 1$
           \While {$i < l$}
                \For {each $\zeta(s_{now}, s_{j})$ in $Z$}
                    \State $\zeta(s_{now}, s_{j})$ を $Z$からポップ
                    \If{$s$が未探索のノード($N(s)=0$)または終了状態のとき}
                        \State $\zeta(s_{now}, s_{j})$ を$k$回$Z$の末尾に追加
                        \State continue
                    \EndIf
                    \State 訪問回数$N(s)$から上位$k$の行動$\{a_1, a_2, ..., a_{k}\}(=\alpha)$を取り出す
                    \For {each $a_i$ in $\alpha$}
                        \State $s_{{next}_j} \gets T(s_{j}, a_i)$
                        \State $\zeta(s_{now},s_{{next}_i})(=\zeta(s_{now}, s_{j}).append({a_i, s_{{next}_i}}))$を$Z$の末尾に追加
                    \EndFor
                    
                \EndFor     
           \EndWhile
           \Return $Z(=\{\zeta(s_{start}, {s'}_1), ..., \zeta(s_{start}, {s'}_{k^l})\})$
        \EndFunction
        \Function {Traverse}{$s, \zeta(s_{start}, s)$}
        \State $s_{now} \gets s$
        \State $\zeta_r \gets \zeta(s_{start}, s)$
        \While {$s_{now}が探索済みかつ終了状態でない$}
            \State $a_t \gets \textrm{argmax}_a N(s_{now}, a)$
            \State $s_n \gets T(s_{now}, a_t)$
            \State $\zeta_r.append({a_t, s_n})$
            \State $s_{now} \gets s_n$
        \EndWhile
        \Return $\zeta_r$
        \EndFunction
       
        
    \end{algorithmic}
\end{algorithm}

\section{比較手法のアルゴリズム}
比較手法の疑似コードをAlgorithm \ref{alg:compare}に示す．疑似コード中のTraverse()は Algorithm\ref{alg:myalg-2}と同一である．
\begin{algorithm}
    \caption{比較手法のアルゴリズム}
    \label{alg:compare}
    \begin{algorithmic}[1]       
        \State $t$: 手法を適用する探索木
        \State $T$: 状態遷移関数
        \State $\zeta(s, s')$: ノード$s$から$s'$までの軌道
        \Function{CompareAlgorithm}{$s, a$}
           \State $s_n \gets T(s, a)$
           \State $\zeta(s, s_n) \gets \{s, a, s_n\}$
           \State $\zeta \gets$ \Call{$s_n, \zeta(s, s_n)$}
           \Return $\zeta$
        \EndFunction
        
        \Function {Traverse}{$s, \zeta(s_{start}, s)$}
            \State $s_{now} \gets s$
            \State $\zeta_r \gets \zeta(s_{start}, s)$
            \While {$s_{now}が探索済みかつ終了状態でない$}
                \State $a_t \gets \textrm{argmax}_a N(s_{now}, a)$
                \State $s_n \gets T(s_{now}, a_t)$
                \State $\zeta_r.append({a_t, s_n})$
                \State $s_{now} \gets s_n$
            \EndWhile
            \Return $\zeta_r$
        \EndFunction
       
        
    \end{algorithmic}
\end{algorithm}


\section{提案手法におけるニューロ補間}
第4章におけるデータ実験，システム実験ではいずれも手法のニューラルネットワークによる補間を行っている．
第4章で示した疑似コードでは未探索のノードにたどり着いた際は走査を終了する．ニューラルネットワークによる補間とはこの場合，
方策$P(s, a)$で訪問回数$N(s, a)$を代用し走査を継続することである．
Algorithm\ref{alg:neuro-1}，Algorithm\ref{alg:neuro-2}にニューロ補間を行う場合の疑似コードを示す（変更部分に下線）．
比較手法に対してニューロ補間を行う場合も同様にTraverse()のコードを変更する．
\begin{algorithm}
    \caption{提案手法のアルゴリズム(ニューロ補間あり)part1}
    \label{alg:neuro-1}
    \small
    \begin{algorithmic}[1]       
        \Function{CollectBoards}{$s, a, l, k$}
           \State $s_{now} \gets T(s, a)$
           \State $Z \gets $ empty queue
            \If{$s$が終了状態のとき}
             \Return  $Z$
            \EndIf
            \If{$s$が未探索のとき}
             \State \underline{方策$P(s)$から上位$k$の行動$\{a_1, a_2, ..., a_{k}\}(=\alpha)$を取り出す}
            \Else
             \State 訪問回数$N(s)$から上位$k$の行動$\{a_1, a_2, ..., a_{k}\}(=\alpha)$を取り出す
            \EndIf
           \For {each $a_i$ in $\alpha$}
             \State $s_{{next}_i} \gets T(s_{now}, a_i)$
             \State $\zeta(s_{now},s_{{next}_i})(=\{s_{now}, a_i, s_{{next}_i}\})$を$Z$の末尾に追加
           \EndFor
           \If{l=1}
             \Return $Z$
           \EndIf
           \State $i \gets 1$
           \While {$i < l$}
                \For {each $\zeta(s_{now}, s_{j})$ in $Z$}
                    \State $\zeta(s_{now}, s_{j})$ を $Z$からポップ
                    \If{$s$終了状態のとき}
                        \State $\zeta(s_{now}, s_{j})$ を$k$回$Z$の末尾に追加
                        \State continue
                    \EndIf
                    \If{$s$が未探索のとき}
                       \State \underline{方策$P(s)$から上位$k$の行動$\{a_1, a_2, ..., a_{k}\}(=\alpha)$を取り出す}
                   \Else
                    \State 訪問回数$N(s)$から上位$k$の行動$\{a_1, a_2, ..., a_{k}\}(=\alpha)$を取り出す
                   \EndIf
                    
                    \For {each $a_i$ in $\alpha$}
                        \State $s_{{next}_j} \gets T(s_{j}, a_i)$
                        \State $\zeta(s_{now},s_{{next}_i})(=\zeta(s_{now}, s_{j}).append({a_i, s_{{next}_i}}))$を$Z$の末尾に追加
                    \EndFor
                    
                \EndFor     
           \EndWhile
           \Return $Z(=\{\zeta(s_{start}, {s'}_1), ..., \zeta(s_{start}, {s'}_{k^l})\})$
        \EndFunction
    \end{algorithmic}
\end{algorithm}
\begin{algorithm}
    \caption{提案手法のアルゴリズム(ニューロ補間あり)part2}
    \label{alg:neuro-1}
    \begin{algorithmic}[1] 
        \Function {Traverse}{$s, \zeta(s_{start}, s)$}
        \State $s_{now} \gets s$
        \State $\zeta_r \gets \zeta(s_{start}, s)$
        \While {$s_{now}$が終了状態でない}
            \If{$s_{now}$が未探索のとき}
                \State \underline{$a_t \gets \textrm{argmax}_a P(s_{now}, a)$}
            \Else
                \State $a_t \gets \textrm{argmax}_a N(s_{now}, a)$
            \EndIf
            \State $s_n \gets T(s_{now}, a_t)$
            \State $\zeta_r.append({a_t, s_n})$
            \State $s_{now} \gets s_n$
        \EndWhile
        \Return $\zeta_r$
        \EndFunction
       
        
    \end{algorithmic}
\end{algorithm}
\section{システム実験における提案手法の変更}
\label{sec:fix}
システム実験では画面の左下に盤面$s$の訪問回数$N(s)$と局面評価$V(s, a)$を表示する．このとき
$V(s, a)$の絶対値（どちらのプレイヤーの勝利に近いか）と予想図の勝敗が異なる場合，ユーザーの混乱を招く可能性がある．
そのため，提案手法では勝敗が$V(s, a)$の絶対値と一致する軌道を表示するように修正を施した．
システム実験用に修正された疑似コードはAlgorithm:\ref{alg:system}となる．（下線が変更部分）
また，提案手法により収集した最終盤面$S=\{s_{edge_1}, s_{edge_2}, ..., s_{edge_{k^l}}\}$は
最終的に４つ以上連続してつながっている石の組み合わせ(fatal group)でグループ化し，最も要素数が多い集合の道筋をユーザーに提示した．

\begin{algorithm}
    \caption{提案手法のアルゴリズム(システム実験)}
    \label{alg:system}
    \begin{algorithmic}[1]       
        
        \Function {Traverse}{$s, \zeta(s_{start}, s)$}
        \State  \underline{$\zeta(s_{start}, s)$から$s_{start}$の次の行動$a$を取り出す}
        \State \underline{$v \gets V(s, a)$}
        \State $s_{now} \gets s$
        \State $\zeta_r \gets \zeta(s_{start}, s)$
        \While {$s_{now}$が終了状態でない}
            \If{$s_{now}$が未探索のとき}
                \State \underline{$a_t \gets \textrm{argmax}_a P(s_{now}, a)$}
            \Else
                \State $a_t \gets \textrm{argmax}_a N(s_{now}, a)$
            \EndIf
            \State $s_n \gets T(s_{now}, a_t)$
            \State $\zeta_r.append({a_t, s_n})$
            \State $s_{now} \gets s_n$
        \EndWhile
        \If{\underline{$v$と$V(s_{now})$の絶対値が異なるとき}}
           \Return null
        \EndIf
        \Return $\zeta_r$
        \EndFunction
       
        
    \end{algorithmic}
\end{algorithm}
