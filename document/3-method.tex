\chapter{提案手法}
関連研究の章ではニューラルネットワークや決定木が内包する説明性の欠如という問題点と説明を加える既存手法の持つ課題について述べた。
本論文ではそれらを踏まえた
\begin{itemize}
	\item 本来ゲームに存在する時系列の要素を含む
	\item 評価基準が勝敗に直結する
    \item 人間のドメイン知識に依存しない
\end{itemize}
説明手法を提案する。
図\ref{fig:mabs}に提案手法の概要を示している。
本手法はある状態$s$と行動$a$の組に対してAIが予想する未来図$O(s)$とそこに至るまでの道筋の集合を取り出し、その傾向を見出すことによるAIの判断
の意図を可視化を目標とする。
以降は未来図$O(s)$と走査が$O(s)$に至るまでに通過したノードの履歴(軌道)$\zeta(s, O(s))$を合わせて進行図と記載する。
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{./figure/mabs.png}
    \caption{提案手法の概要}
    \label{fig:mabs}
\end{figure}


\section{提案手法のアルゴリズム}
本手法はAlphaZeroシステムのニューラルネットワークと木探索部分のうち、主に木探索の部分を対象に適用される。
本手法では決定木の判断を説明する際に最も有用な部分を決定木から抽出することを主な目的としており、アルゴリズムはボードゲームAIに留まらず決定木構造を持つ多くのシステムに応用可能である。
アルゴリズムの流れは以下の通りである。
図\ref{fig:step1-2}、図\ref{fig:step3-4}はステップごとのアルゴリズムのイメージ図である。
\begin{enumerate}
    \item 説明を付与する状態と行動の組$(s_{start}, a)$を選択する。
    このとき注目している状態$s_{now}, a_{now}$はそれぞれ
    \begin{equation}
        {s_{now}=s_{start}}
    \end{equation}
    \begin{equation}
        {a_{now}=a}
    \end{equation}
    とする。
    \item 以下の流れを$l$ステップ分繰り返す。\\
    決定木中の注目しているノード$s_{now}$における訪問回数$N(s_{now})$中の上位$k$個分の行動$\{a_1, a_2, ..., a_{k}\}(a_iはk番目に有望な行動とする)$を取り出す。
    $s_{now}$から行動$\{a_1, a_2, ..., a_{k}\}$を取ることでたどり着く各ノード\\
    $\{s_{next_1}, s_{next_2}, ..., s_{next_{k}}\}(s_{next_i}=T(s_{now}, a_i), Tは遷移関数)$に対して同様の操作を繰り返す。
    
    
    \item 集めた$k$の$l$乗個のノード$\{{s}'_{1}, {s'}_{2}, ..., {s'}_{k^l}\}$のそれぞれ${s'}_{i}(i=1, 2, ..., k^l)$に対して以下の操作を再帰的に繰り返す。
    ${s'}_{i}$における方策$P({s'}_{i})$中の最も有望な行動$a_{promising}$と${s'}_{next_i}=T({s'}_i, a_{promising})$を記録する。
    そのようにして記録した$\{{s'}_{next_1}, {s'}_{next_2}, ..., {s'}_{next_{k^l}}\}$のそれぞれ${s'}_{next_j}(j=1, 2, ..., k^l)$にも同様の操作を盤面ノードが決定木の端に辿り着くまで行う。
    \item step3によってたどり着いた$k^l$個のノードによる集合$S=\{s_{edge_1}, s_{edge_2}, ..., s_{edge_{k^l}}\}$を任意の共通項$c$によっていくつかの副集合$\{S_1, S_2, ..., S_q\}$に分ける。
    \item 共通項で括られた各集合$\{S_1, S_2, ..., S_q\}$のうち、最も要素数が多いもの$S_{max}$中の各要素$\{s_{e_1}, s_{e_2}, ...,  s_{e_u}\}$と各要素に対応する軌道$\{\rm{{\zeta}_{s_{e_1}}}, \rm{{\zeta}_{s_{e_2}}}, ...,  \rm{{\zeta}_{s_{e_u}}}\}$を抽出する。
\end{enumerate}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{./figure/1-2.png}
    \caption{提案アルゴリズムの概要(step1$\sim$ 2)}
    \label{fig:step1-2}
\end{figure}
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{./figure/3-4.png}
    \caption{提案アルゴリズムの概要(step3$\sim $4)}
    \label{fig:step3-4}
\end{figure}

このアルゴリズムを要約すると、図\ref{fig:merit}のようにある局面$s$と行動$a$の組み合わせから辿り着きやすい結末$O(s, a)$を抽出し、同時に$O(s, a)$に至るまでの複数の道筋を抽出すると表現できる。
調査を行う者が複数の道筋を観察できることで、
共通する傾向や法則性を見出せるというメリットが存在する。これは第2章で述べたような最も可能性が高い一つの分岐を示す、といったような情報が単一である従来の手法には不可能である。
提案手法の疑似コードは付録\ref{chap:alg}に記載している。

\begin{figure}[t]
    \includegraphics[width=200pt]{./figure/merit.png}
	\caption{提案手法と既存手法}
	\label{fig:merit}
\end{figure}




付録\ref{chap:data}で示すようにconnect4タスクにおいて収集される軌道の集合においては末端部分のいくつかの選択が共通している傾向が確認された。
そのため状態と行動の組$(s, a)$から$O(s, a)$という結果を予測する過程で$O(s, a)$から末尾の数手を取り除いた版面$d$にたどり着く傾向の発見などの知識獲得が記載される。
\section{importance}
前章で述べたように、エピソード中の各状態$s$の重要度$I(s)$の定義を以下のように定めた。
\begin{equation}
    \label{new-imp}
	{I(s)=V[Q'] (Q'=[\rm{max}Q(s, a), \rm{secondMax}Q(s, a), ..., \rm{thirdQuantile}Q(s, a)])}
\end{equation}
つまり、現在の状態$s$に対する行動の集合$A(={a_1, a_2, ..., a_N})$とした際の行動価値関数の集合${Q(s, a_1), Q(s, a_2), ..., Q(s, a_N)}$のうち値の大きさが上位75
\%の成分で構成される集合の分散として重要度$I(s)$を定義する。
これは次の一手で辿り着きうる収益の予想の揺らぎの幅を意味しており、先述した盤面の対称性や悪い選択肢の影響が大きくなる可能性の軽減が期待できる。

